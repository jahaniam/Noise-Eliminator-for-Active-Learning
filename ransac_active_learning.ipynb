{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14980, 15)\n",
      "           AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
      "0      4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
      "1      4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
      "2      4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
      "3      4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
      "4      4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "14975  4281.03  3990.26  4245.64  4116.92  4333.85  4614.36  4074.87  4625.64   \n",
      "14976  4276.92  3991.79  4245.13  4110.77  4332.82  4615.38  4073.33  4621.54   \n",
      "14977  4277.44  3990.77  4246.67  4113.85  4333.33  4615.38  4072.82  4623.59   \n",
      "14978  4284.62  3991.79  4251.28  4122.05  4334.36  4616.41  4080.51  4628.72   \n",
      "14979  4287.69  3997.44  4260.00  4121.03  4333.33  4616.41  4088.72  4638.46   \n",
      "\n",
      "            P8       T8      FC6       F4       F8      AF4  Eye_detection  \n",
      "0      4222.05  4238.46  4211.28  4280.51  4635.90  4393.85              0  \n",
      "1      4210.77  4226.67  4207.69  4279.49  4632.82  4384.10              0  \n",
      "2      4207.69  4222.05  4206.67  4282.05  4628.72  4389.23              0  \n",
      "3      4217.44  4235.38  4210.77  4287.69  4632.31  4396.41              0  \n",
      "4      4210.77  4244.10  4212.82  4288.21  4632.82  4398.46              0  \n",
      "...        ...      ...      ...      ...      ...      ...            ...  \n",
      "14975  4203.08  4221.54  4171.28  4269.23  4593.33  4340.51              1  \n",
      "14976  4194.36  4217.44  4162.56  4259.49  4590.26  4333.33              1  \n",
      "14977  4193.33  4212.82  4160.51  4257.95  4591.79  4339.49              1  \n",
      "14978  4200.00  4220.00  4165.64  4267.18  4596.41  4350.77              1  \n",
      "14979  4212.31  4226.67  4167.69  4274.36  4597.95  4350.77              1  \n",
      "\n",
      "[14980 rows x 15 columns]\n",
      "       Eye_detection\n",
      "0                  0\n",
      "1                  0\n",
      "2                  0\n",
      "3                  0\n",
      "4                  0\n",
      "...              ...\n",
      "14975              1\n",
      "14976              1\n",
      "14977              1\n",
      "14978              1\n",
      "14979              1\n",
      "\n",
      "[14980 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "random_state = 8\n",
    "data = pd.read_csv('EEG_Eye_State.csv')\n",
    "print(data.shape)\n",
    "print(data)\n",
    "X = data.loc[:,data.columns !='Eye_detection']\n",
    "# y = data.loc[:,data.columns =='Eye_detection']\n",
    "y = np.array(data['Eye_detection'],dtype=np.float64)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on raw :  57.510013351134845\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state)\n",
    "# Train a multi-layer perceptron\n",
    "clf0 = MLPClassifier(hidden_layer_sizes=(100,100),random_state=random_state, verbose=False, max_iter=1000)\n",
    "clf0.fit(X_train, y_train)\n",
    "# Predict accuracy of classifier\n",
    "y_pred = clf0.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy on raw : ', acc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on raw scaled :  90.82109479305741\n"
     ]
    }
   ],
   "source": [
    "#Feature scaling\n",
    "scaled_X = preprocessing.scale(X)\n",
    "# Split into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state = random_state)\n",
    "# Train a multi-layer perceptron\n",
    "clf0 = MLPClassifier(hidden_layer_sizes=(100,100),random_state=random_state, verbose=False, max_iter=1000)\n",
    "clf0.fit(X_train, y_train)\n",
    "# Predict accuracy of classifier\n",
    "y_pred = clf0.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy on raw scaled : ', acc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ split data #######################\n",
    "# train: 0.1 total  \n",
    "# pool: 0.5 total\n",
    "# valid: 0.2 total\n",
    "# test: 0.2 total\n",
    "# ################################################# \n",
    "\n",
    "def split_data(scaled_X, y, noise_probability = 0.0):\n",
    "    noise_gt = np.zeros_like(y)\n",
    "    noise_proba = np.zeros_like(y)\n",
    "    y_with_noise = np.stack((y,noise_gt,noise_proba),axis=1) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y_with_noise, test_size = 0.2, random_state = random_state)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.0834, random_state = random_state)\n",
    "    np.random.seed(random_state)\n",
    "    #adding noise to train and pool ,  validation split and test split don't have noise\n",
    "    y_train_noise = np.random.random(y_train.shape[0])<noise_probability\n",
    "    y_train[:,0] = np.abs(y_train_noise -y_train[:,0])\n",
    "    y_train[:,1] = y_train_noise.astype(np.float32)\n",
    "    \n",
    "    X_train, X_pool, y_train, y_pool = train_test_split(X_train, y_train, test_size = 0.6873, random_state = random_state)\n",
    "\n",
    "    print (\"---------\")\n",
    "    print(f\"total: {y.size}\\ntrain: {y_train.shape} -> {y_train.shape[0]/y.size:.2f}x \\npool: {y_pool.shape} -> {y_pool.shape[0]/y.size:.2f}x\")\n",
    "    print(f\"valid: {y_valid.shape[0]} -> {y_valid.shape[0]/y.size:.2f}x \\ntest: {y_test.shape[0]} -> {y_test.shape[0]/y.size:.2f}x\")\n",
    "    print (\"---------\")\n",
    "    \n",
    "    return X_train, X_pool, X_valid, X_test, y_train, y_pool, y_valid, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005.0\n",
      "(3434, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.sum(y_train[:,1]))\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "total: 14980\n",
      "train: (3434, 3) -> 0.23x \n",
      "pool: (7550, 3) -> 0.50x\n",
      "valid: 1000 -> 0.07x \n",
      "test: 2996 -> 0.20x\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_pool, X_valid, X_test, y_train, y_pool, y_valid, y_test = split_data(scaled_X, y, noise_probability=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_most_ambigious(y_proba_pred, ambigious_amount =1, method='least_confidence') -> list:\n",
    "    \"\"\"This function finds most ambigous predicted data and returns their indexes. It assumes\n",
    "        we have only two class.\n",
    "\n",
    "\tArgs:\n",
    "\t\ty_proba_pred ([list]): [predicted probabilities]\n",
    "\t\ty ([list]): [ground truth labels]\n",
    "\t\tambigious_amount (int, optional): [quantity of most ambigious]. Defaults to 1.\n",
    "\t\tmethod (str, optional): [method type i.e, least_confidence]. Defaults to 'least_confidence'.\n",
    "\n",
    "\tReturns:\n",
    "\t\tindexes ([list]): [indexes of the most ambigious]\n",
    "\t\"\"\"\n",
    "    indexes = []\n",
    "    if method == 'least_confidence':\n",
    "        difference = np.abs(y_proba_pred[:,0]-y_proba_pred[:,1])\n",
    "        indexes = np.argsort(difference)[:ambigious_amount]\n",
    "    else:\n",
    "        print(\"method is not defined. Use 'least_confidence'\")\n",
    "        \n",
    "    return indexes\n",
    "\n",
    "def train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, model, ambigious_amount=1  , method='least_confidence'):\n",
    "\n",
    "    y_proba_pred = model.predict_proba(X_pool)\n",
    "\n",
    "    most_ambigious_indexes = find_most_ambigious(y_proba_pred, ambigious_amount=ambigious_amount, method='least_confidence')\n",
    "    \n",
    "    X_train = np.append(X_train,X_pool[most_ambigious_indexes],axis = 0)\n",
    "    y_train = np.append(y_train, y_pool[most_ambigious_indexes],axis = 0)\n",
    "    X_pool = np.delete(X_pool,most_ambigious_indexes,axis=0)\n",
    "    y_pool = np.delete(y_pool,most_ambigious_indexes,axis=0)\n",
    "#     new_y_train = logodds_to_y(y_train)\n",
    "    model.fit(X_train,y_train[:,0])\n",
    "    acc = model.score(X_test,y_test[:,0])\n",
    "\n",
    "    return X_train, y_train, X_pool, y_pool, model, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_logodds(y_train, inlier_idx, outlier_idx):\n",
    "    likelihood_of_noise = 0.7\n",
    "    log_ratio_likelihood_of_noise = np.log(likelihood_of_noise/(1-likelihood_of_noise))\n",
    "    y_train[outlier_idx,2] += log_ratio_likelihood_of_noise\n",
    "    y_train[inlier_idx,2] -= log_ratio_likelihood_of_noise\n",
    "    return y_train\n",
    "\n",
    "def logodds_to_y(y_train):\n",
    "    p_noise = np.exp(y_train[:,2])/(1+np.exp(y_train[:,2]))\n",
    "    new_y_train =  np.abs(y_train[:,0] - p_noise)\n",
    "    return new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00615824 0.03263497 0.00615824 ... 0.3        0.3        0.3       ]\n",
      "(3734,)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "total: 14980\n",
      "train: (3434, 3) -> 0.23x \n",
      "pool: (7550, 3) -> 0.50x\n",
      "valid: 1000 -> 0.07x \n",
      "test: 2996 -> 0.20x\n",
      "---------\n",
      "train size: (4434, 3)\n",
      "iteration -1:   accuracy = 0.7360\n",
      "--\n",
      "train size: (4484, 3)\n",
      "iteration 0:   accuracy = 0.73397863818425\n",
      "--\n",
      "train size: (4534, 3)\n",
      "iteration 1:   accuracy = 0.75200267022697\n",
      "--\n",
      "train size: (4584, 3)\n",
      "iteration 2:   accuracy = 0.72329773030708\n",
      "--\n",
      "train size: (4634, 3)\n",
      "iteration 3:   accuracy = 0.73731642189586\n",
      "--\n",
      "train size: (4684, 3)\n",
      "iteration 4:   accuracy = 0.72797062750334\n",
      "--\n",
      "train size: (4734, 3)\n",
      "iteration 5:   accuracy = 0.74899866488652\n",
      "--\n",
      "train size: (4734, 3)\n"
     ]
    }
   ],
   "source": [
    "## pure active learning\n",
    "X_train, X_pool, X_valid, X_test, y_train, y_pool, y_valid, y_test = split_data(scaled_X, y, noise_probability=0.3)\n",
    "X_train = np.append(X_train,X_valid,axis=0)\n",
    "y_train = np.append(y_train,y_valid,axis=0)\n",
    "\n",
    "print(f\"train size: {y_train.shape}\")\n",
    "clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state, max_iter=1000)\n",
    "\n",
    "clf1.fit(X_train, y_train[:,0])\n",
    "acc = clf1.score(X_test,y_test[:,0])\n",
    "\n",
    "print (f\"iteration -1:   accuracy = {acc:0.4f}\")\n",
    "\n",
    "print (\"--\")\n",
    "K = 6\n",
    "for k in range(K):\n",
    "    X_train, y_train, X_pool, y_pool, clf1, acc = train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, model=clf1, ambigious_amount=50 , method='least_confidence')\n",
    "    print(f\"train size: {y_train.shape}\")\n",
    "\n",
    "    print (f\"iteration {k}:   accuracy = {acc:0.14f}\")\n",
    "    print (\"--\")\n",
    "\n",
    "print(f\"train size: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "total: 14980\n",
      "train: (3434, 3) -> 0.23x \n",
      "pool: (7550, 3) -> 0.50x\n",
      "valid: 1000 -> 0.07x \n",
      "test: 2996 -> 0.20x\n",
      "---------\n",
      "iteration -1:   accuracy = 0.6756\n",
      "--\n",
      "################ Outer iteration 0 ################ \n",
      "AL iteration 0:   accuracy = 0.6729\n",
      "train size: (3484, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.66100000000000\n",
      "Ransac iteration 1:   accuracy = 0.65900000000000\n",
      "Ransac iteration 2:   accuracy = 0.66700000000000\n",
      "Ransac iteration 3:   accuracy = 0.66000000000000\n",
      "Ransac iteration 4:   accuracy = 0.64500000000000\n",
      "Ransac iteration 5:   accuracy = 0.63700000000000\n",
      "Ransac iteration 6:   accuracy = 0.67500000000000\n",
      "Ransac iteration 7:   accuracy = 0.64500000000000\n",
      "Ransac iteration 8:   accuracy = 0.66500000000000\n",
      "Ransac iteration 9:   accuracy = 0.66200000000000\n",
      "----------------\n",
      "train size: (3484, 3)\n",
      "Final accuracy = 0.6836\n",
      "----------------\n",
      "################ Outer iteration 1 ################ \n",
      "AL iteration 0:   accuracy = 0.6766\n",
      "train size: (3534, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.65700000000000\n",
      "Ransac iteration 1:   accuracy = 0.64500000000000\n",
      "Ransac iteration 2:   accuracy = 0.67700000000000\n",
      "Ransac iteration 3:   accuracy = 0.66000000000000\n",
      "Ransac iteration 4:   accuracy = 0.64600000000000\n",
      "Ransac iteration 5:   accuracy = 0.67500000000000\n",
      "Ransac iteration 6:   accuracy = 0.66900000000000\n",
      "Ransac iteration 7:   accuracy = 0.66500000000000\n",
      "Ransac iteration 8:   accuracy = 0.65100000000000\n",
      "Ransac iteration 9:   accuracy = 0.66800000000000\n",
      "----------------\n",
      "train size: (3534, 3)\n",
      "Final accuracy = 0.6842\n",
      "----------------\n",
      "################ Outer iteration 2 ################ \n",
      "AL iteration 0:   accuracy = 0.6842\n",
      "train size: (3584, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.69200000000000\n",
      "Ransac iteration 1:   accuracy = 0.69600000000000\n",
      "Ransac iteration 2:   accuracy = 0.68300000000000\n",
      "Ransac iteration 3:   accuracy = 0.69200000000000\n",
      "Ransac iteration 4:   accuracy = 0.69200000000000\n",
      "Ransac iteration 5:   accuracy = 0.69600000000000\n",
      "Ransac iteration 6:   accuracy = 0.71400000000000\n",
      "Ransac iteration 7:   accuracy = 0.69800000000000\n",
      "Ransac iteration 8:   accuracy = 0.69500000000000\n",
      "Ransac iteration 9:   accuracy = 0.66600000000000\n",
      "----------------\n",
      "train size: (3584, 3)\n",
      "Final accuracy = 0.6913\n",
      "----------------\n",
      "################ Outer iteration 3 ################ \n",
      "AL iteration 0:   accuracy = 0.6802\n",
      "train size: (3634, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.67100000000000\n",
      "Ransac iteration 1:   accuracy = 0.63700000000000\n",
      "Ransac iteration 2:   accuracy = 0.68700000000000\n",
      "Ransac iteration 3:   accuracy = 0.66200000000000\n",
      "Ransac iteration 4:   accuracy = 0.66800000000000\n",
      "Ransac iteration 5:   accuracy = 0.67700000000000\n",
      "Ransac iteration 6:   accuracy = 0.67500000000000\n",
      "Ransac iteration 7:   accuracy = 0.67900000000000\n",
      "Ransac iteration 8:   accuracy = 0.68400000000000\n",
      "Ransac iteration 9:   accuracy = 0.66400000000000\n",
      "----------------\n",
      "train size: (3634, 3)\n",
      "Final accuracy = 0.6866\n",
      "----------------\n",
      "################ Outer iteration 4 ################ \n",
      "AL iteration 0:   accuracy = 0.6832\n",
      "train size: (3684, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.69400000000000\n",
      "Ransac iteration 1:   accuracy = 0.66200000000000\n",
      "Ransac iteration 2:   accuracy = 0.66400000000000\n",
      "Ransac iteration 3:   accuracy = 0.69100000000000\n",
      "Ransac iteration 4:   accuracy = 0.67500000000000\n",
      "Ransac iteration 5:   accuracy = 0.67700000000000\n",
      "Ransac iteration 6:   accuracy = 0.69600000000000\n",
      "Ransac iteration 7:   accuracy = 0.66300000000000\n",
      "Ransac iteration 8:   accuracy = 0.67600000000000\n",
      "Ransac iteration 9:   accuracy = 0.69500000000000\n",
      "----------------\n",
      "train size: (3684, 3)\n",
      "Final accuracy = 0.6923\n",
      "----------------\n",
      "################ Outer iteration 5 ################ \n",
      "AL iteration 0:   accuracy = 0.6796\n",
      "train size: (3734, 3)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.68200000000000\n",
      "Ransac iteration 1:   accuracy = 0.67600000000000\n",
      "Ransac iteration 2:   accuracy = 0.69800000000000\n",
      "Ransac iteration 3:   accuracy = 0.66900000000000\n",
      "Ransac iteration 4:   accuracy = 0.69200000000000\n",
      "Ransac iteration 5:   accuracy = 0.66500000000000\n",
      "Ransac iteration 6:   accuracy = 0.67700000000000\n",
      "Ransac iteration 7:   accuracy = 0.67700000000000\n",
      "Ransac iteration 8:   accuracy = 0.68900000000000\n",
      "Ransac iteration 9:   accuracy = 0.68300000000000\n",
      "----------------\n",
      "train size: (3734, 3)\n",
      "Final accuracy = 0.6872\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "## Active learning with Ransac\n",
    "\n",
    "X_train, X_pool, X_valid, X_test, y_train, y_pool, y_valid, y_test = split_data(scaled_X, y,noise_probability = 0.3)\n",
    "\n",
    "# X_train = np.append(X_train,X_valid,axis=0)\n",
    "# y_train = np.append(y_train,y_valid,axis=0)\n",
    "\n",
    "clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state,max_iter=1000)\n",
    "clf1.fit(X_train, y_train[:,0])\n",
    "acc = clf1.score(X_test,y_test[:,0])\n",
    "print (f\"iteration -1:   accuracy = {acc:0.4f}\")\n",
    "print (\"--\")\n",
    "\n",
    "#################\n",
    "K = 1\n",
    "M = 10\n",
    "N = 6\n",
    "\n",
    "#### in total N*k times active learning iterations, N*M times Ransac iterations ####\n",
    "for n in range(N):\n",
    "\n",
    "    print(f\"################ Outer iteration {n} ################ \")\n",
    "\n",
    "    ############ k iteration active learning -> everytime get m 10 ############\n",
    "    for k in range(K):\n",
    "        X_train, y_train, X_pool, y_pool, clf1, acc = train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, clf1, ambigious_amount=50 , method='least_confidence')\n",
    "        print (f\"AL iteration {k}:   accuracy = {acc:0.4f}\")\n",
    "    print(f\"train size: {y_train.shape}\")\n",
    "    print (\"--------\")\n",
    "    \n",
    "    #####################################################\n",
    "\n",
    "    stats_history =[]\n",
    "    for m in range(M):\n",
    "        ransac_random_state = random_state + m # to make sure repeatable results\n",
    "        indices = np.arange(y_train.shape[0])\n",
    "\n",
    "        r_X_train,r_X_outlier, r_y_train, r_y_outlier, r_X_train_idx, r_X_outlier_idx = train_test_split(X_train, y_train, indices, test_size = 0.05, random_state = ransac_random_state)\n",
    "        clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state, max_iter=1000)\n",
    "        clf1.fit(r_X_train, r_y_train[:,0])\n",
    "        acc = clf1.score(X_valid, y_valid[:,0])\n",
    "        print (f\"Ransac iteration {m}:   accuracy = {acc:0.14f}\")\n",
    "        \n",
    "        stat = {\"model\":clf1, \"accuracy\":acc, 'X_train_inlier_idx':r_X_train_idx, 'X_train_outlier_idx':r_X_outlier_idx}\n",
    "        \n",
    "        stats_history.append(stat)\n",
    "\n",
    "    # Take the best model and 95% data that gives best accuracy     \n",
    "    best = sorted(stats_history, key=lambda x: x[\"accuracy\"])[-1]\n",
    "    clf1 = best[\"model\"]\n",
    "    inlier_idx = best['X_train_inlier_idx']\n",
    "    outlier_idx = best['X_train_outlier_idx']\n",
    "    y_train = update_logodds(y_train, inlier_idx, outlier_idx)\n",
    "\n",
    "    print (\"----------------\")\n",
    "\n",
    "    acc = clf1.score(X_test, y_test[:,0])\n",
    "    print(f\"train size: {y_train.shape}\")\n",
    "    print (f\"Final accuracy = {acc:0.4f}\")\n",
    "    print (\"----------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3734, 3)\n",
      "total: 1080\n",
      "found: 9\n",
      "correct: 2\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "found = 0\n",
    "correct = 0\n",
    "y_train_2 = np.zeros_like(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "#     print(y_train[i])\n",
    "#     y_train_2[i] = y_train[i]\n",
    "    \n",
    "    if y_train[i][1]==1.0:\n",
    "        total+=1\n",
    "    if y_train[i][1]==1.0 and y_train[i][2]>0:\n",
    "        correct +=1\n",
    "    if y_train[i][2]>0:\n",
    "        found +=1\n",
    "#         y_train_2[i][0] = np.abs(1-y_train[i][0])\n",
    "        \n",
    "#     if y_train[i][1]==0 and y_train[i][2]<0:\n",
    "#         correct +=1\n",
    "#         y_train_2[i][0] = np.abs(1-y_train[i][0])\n",
    "\n",
    "#     print(y_train[i])\n",
    "\n",
    "\n",
    "print('total:',total)\n",
    "print('found:',found)\n",
    "print('correct:',correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration -1:   accuracy = 0.5557\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state,max_iter=1000)\n",
    "clf1.fit(X_train, np.abs(y_train[:,0]-y_train[:,1]))\n",
    "acc = clf1.score(X_test,y_test[:,0])\n",
    "print (f\"iteration -1:   accuracy = {acc:0.4f}\")\n",
    "print (\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
