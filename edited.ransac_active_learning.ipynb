{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14980, 15)\n           AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n0      4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n1      4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n2      4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n3      4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n4      4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n...        ...      ...      ...      ...      ...      ...      ...      ...   \n14975  4281.03  3990.26  4245.64  4116.92  4333.85  4614.36  4074.87  4625.64   \n14976  4276.92  3991.79  4245.13  4110.77  4332.82  4615.38  4073.33  4621.54   \n14977  4277.44  3990.77  4246.67  4113.85  4333.33  4615.38  4072.82  4623.59   \n14978  4284.62  3991.79  4251.28  4122.05  4334.36  4616.41  4080.51  4628.72   \n14979  4287.69  3997.44  4260.00  4121.03  4333.33  4616.41  4088.72  4638.46   \n\n            P8       T8      FC6       F4       F8      AF4  Eye_detection  \n0      4222.05  4238.46  4211.28  4280.51  4635.90  4393.85              0  \n1      4210.77  4226.67  4207.69  4279.49  4632.82  4384.10              0  \n2      4207.69  4222.05  4206.67  4282.05  4628.72  4389.23              0  \n3      4217.44  4235.38  4210.77  4287.69  4632.31  4396.41              0  \n4      4210.77  4244.10  4212.82  4288.21  4632.82  4398.46              0  \n...        ...      ...      ...      ...      ...      ...            ...  \n14975  4203.08  4221.54  4171.28  4269.23  4593.33  4340.51              1  \n14976  4194.36  4217.44  4162.56  4259.49  4590.26  4333.33              1  \n14977  4193.33  4212.82  4160.51  4257.95  4591.79  4339.49              1  \n14978  4200.00  4220.00  4165.64  4267.18  4596.41  4350.77              1  \n14979  4212.31  4226.67  4167.69  4274.36  4597.95  4350.77              1  \n\n[14980 rows x 15 columns]\n[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "random_state = 8\n",
    "data = pd.read_csv('EEG_Eye_State.csv')\n",
    "print(data.shape)\n",
    "print(data)\n",
    "X = data.loc[:,data.columns !='Eye_detection']\n",
    "y = np.array(data['Eye_detection'])\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on raw :  44.45927903871829\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state)\n",
    "# Train a multi-layer perceptron\n",
    "clf0 = MLPClassifier(hidden_layer_sizes=(100,100),random_state=random_state, verbose=False, max_iter=1000)\n",
    "clf0.fit(X_train, y_train)\n",
    "# Predict accuracy of classifier\n",
    "y_pred = clf0.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy on raw : ', acc*100)\n"
   ]
  },
  {
   "source": [
    "#Feature scaling\n",
    "scaled_X = preprocessing.scale(X)\n",
    "# Split into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state = random_state)\n",
    "# Train a multi-layer perceptron\n",
    "clf0 = MLPClassifier(hidden_layer_sizes=(100,100),random_state=random_state, verbose=False, max_iter=1000)\n",
    "clf0.fit(X_train, y_train)\n",
    "# Predict accuracy of classifier\n",
    "y_pred = clf0.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy on raw scaled : ', acc*100)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on raw scaled :  90.82109479305741\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ split data #######################\n",
    "# train: 0.2 total  \n",
    "# pool: 0.6 total\n",
    "# test: 0.2 total\n",
    "# ################################################# \n",
    "\n",
    "def split_data(scaled_X, y, noise_probability = 0.0, add_noise_to_train=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state = random_state)\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    X_train, X_pool,y_train, y_pool = train_test_split(X_train, y_train, test_size = 0.75 , random_state = random_state)\n",
    "    if add_noise_to_train:\n",
    "    #adding noise to train\n",
    "        y_train = np.abs((np.random.random(y_train.shape)<noise_probability).astype(int)  -y_train)  # -> either |1-y_train|,or |0-y_train| for each data sample\n",
    "    #adding noise to pool\n",
    "    y_pool = np.abs((np.random.random(y_pool.shape)<noise_probability).astype(int)  -y_pool)  # -> either |1-y_pool|,or |0-y_pool| for each data sample\n",
    "\n",
    "    print (\"---------\")\n",
    "    print(f\"total: {y.size}\\ntrain: {y_train.size} -> {y_train.size/y.size:.2f}x \\npool: {y_pool.size} -> {y_pool.size/y.size:.2f}x \\ntest: {y_test.size} -> {y_test.size/y.size:.2f}x\")\n",
    "    print (\"---------\")\n",
    "    return X_train, X_pool, X_test, y_train, y_pool, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_most_ambigious(y_proba_pred, y, ambigious_amount =1, method='least_confidence') -> list:\n",
    "    \"\"\"This function finds most ambigous predicted data and returns their indexes. It assumes\n",
    "        we have only two class.\n",
    "\n",
    "\tArgs:\n",
    "\t\ty_proba_pred ([list]): [predicted probabilities]\n",
    "\t\ty ([list]): [ground truth labels]\n",
    "\t\tambigious_amount (int, optional): [quantity of most ambigious]. Defaults to 1.\n",
    "\t\tmethod (str, optional): [method type i.e, least_confidence]. Defaults to 'least_confidence'.\n",
    "\n",
    "\tReturns:\n",
    "\t\tindexes ([list]): [indexes of the most ambigious]\n",
    "\t\"\"\"\n",
    "    indexes = []\n",
    "    if method == 'least_confidence':\n",
    "        difference = np.abs(y_proba_pred[:,0]-y_proba_pred[:,1])\n",
    "        indexes = np.argsort(difference)[:ambigious_amount]\n",
    "    else:\n",
    "        print(\"method is not defined. Use 'least_confidence'\")\n",
    "        \n",
    "    return indexes\n",
    "\n",
    "def train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, model, ambigious_amount=1  , method='least_confidence'):\n",
    "\n",
    "    y_proba_pred = model.predict_proba(X_pool)\n",
    "\n",
    "    most_ambigious_indexes = find_most_ambigious(y_proba_pred, y_pool, ambigious_amount =ambigious_amount, method='least_confidence')\n",
    "    \n",
    "    X_train = np.append(X_train,X_pool[most_ambigious_indexes],axis = 0)\n",
    "    y_train = np.append(y_train, y_pool[most_ambigious_indexes])\n",
    "    X_pool = np.delete(X_pool,most_ambigious_indexes,axis=0)\n",
    "    y_pool = np.delete(y_pool,most_ambigious_indexes)\n",
    "    model.fit(X_train,y_train)\n",
    "    acc = model.score(X_test,y_test)\n",
    "\n",
    "    return X_train, y_train, X_pool, y_pool, model, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------\n",
      "total: 14980\n",
      "train: 2996 -> 0.20x \n",
      "pool: 8988 -> 0.60x \n",
      "test: 2996 -> 0.20x\n",
      "---------\n",
      "iteration -1:   accuracy = 0.82911\n",
      "--\n",
      "iteration 0:   accuracy = 0.82877\n",
      "--\n",
      "iteration 1:   accuracy = 0.83244\n",
      "--\n",
      "iteration 2:   accuracy = 0.84146\n",
      "--\n",
      "iteration 3:   accuracy = 0.82977\n",
      "--\n",
      "iteration 4:   accuracy = 0.83578\n",
      "--\n",
      "iteration 5:   accuracy = 0.83645\n",
      "--\n",
      "iteration 6:   accuracy = 0.83778\n",
      "--\n",
      "iteration 7:   accuracy = 0.83478\n",
      "--\n",
      "iteration 8:   accuracy = 0.83111\n",
      "--\n",
      "iteration 9:   accuracy = 0.84680\n",
      "--\n",
      "train size: (3996,)\n"
     ]
    }
   ],
   "source": [
    "## pure active learning\n",
    "noise_probability = 0.2\n",
    "ambigious_amount = 100\n",
    "K = 10\n",
    "add_noise_to_train = True  # pool always has noise\n",
    "#############################\n",
    "X_train, X_pool, X_test, y_train, y_pool, y_test = split_data(scaled_X, y, noise_probability=noise_probability, add_noise_to_train=add_noise_to_train)\n",
    "clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state)\n",
    "clf1.fit(X_train, y_train)\n",
    "acc = clf1.score(X_test,y_test)\n",
    "\n",
    "print (f\"iteration -1:   accuracy = {acc:0.5f}\")\n",
    "print (\"--\")\n",
    "\n",
    "for k in range(K):\n",
    "    X_train, y_train, X_pool, y_pool, clf1, acc = train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, model=clf1, ambigious_amount=ambigious_amount , method='least_confidence')\n",
    "    print (f\"iteration {k}:   accuracy = {acc:0.5f}\")\n",
    "    print (\"--\")\n",
    "\n",
    "print(f\"train size: {y_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------\n",
      "total: 14980\n",
      "train: 2996 -> 0.20x \n",
      "pool: 8988 -> 0.60x \n",
      "test: 2996 -> 0.20x\n",
      "---------\n",
      "iteration -1:   accuracy = 0.82911\n",
      "--\n",
      "################ Outer iteration 0 ################ \n",
      "AL iteration 0:   accuracy = 0.82877\n",
      "AL iteration 1:   accuracy = 0.83244\n",
      "train size: (3196,)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.82810\n",
      "Ransac iteration 1:   accuracy = 0.82710\n",
      "Ransac iteration 2:   accuracy = 0.83344\n",
      "Ransac iteration 3:   accuracy = 0.82076\n",
      "Ransac iteration 4:   accuracy = 0.83344\n",
      "Ransac iteration 5:   accuracy = 0.83511\n",
      "Ransac iteration 6:   accuracy = 0.82844\n",
      "Ransac iteration 7:   accuracy = 0.83311\n",
      "Ransac iteration 8:   accuracy = 0.83211\n",
      "Ransac iteration 9:   accuracy = 0.82610\n",
      "----------------\n",
      "train size: (3036,)\n",
      "Final accuracy = 0.83511\n",
      "----------------\n",
      "################ Outer iteration 1 ################ \n",
      "AL iteration 0:   accuracy = 0.83044\n",
      "AL iteration 1:   accuracy = 0.83545\n",
      "train size: (3236,)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.83478\n",
      "Ransac iteration 1:   accuracy = 0.82543\n",
      "Ransac iteration 2:   accuracy = 0.82243\n",
      "Ransac iteration 3:   accuracy = 0.83645\n",
      "Ransac iteration 4:   accuracy = 0.83511\n",
      "Ransac iteration 5:   accuracy = 0.82844\n",
      "Ransac iteration 6:   accuracy = 0.82744\n",
      "Ransac iteration 7:   accuracy = 0.83244\n",
      "Ransac iteration 8:   accuracy = 0.82677\n",
      "Ransac iteration 9:   accuracy = 0.83077\n",
      "----------------\n",
      "train size: (3074,)\n",
      "Final accuracy = 0.83645\n",
      "----------------\n",
      "################ Outer iteration 2 ################ \n",
      "AL iteration 0:   accuracy = 0.83578\n",
      "AL iteration 1:   accuracy = 0.83244\n",
      "train size: (3274,)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.83178\n",
      "Ransac iteration 1:   accuracy = 0.83044\n",
      "Ransac iteration 2:   accuracy = 0.83244\n",
      "Ransac iteration 3:   accuracy = 0.83478\n",
      "Ransac iteration 4:   accuracy = 0.83712\n",
      "Ransac iteration 5:   accuracy = 0.82043\n",
      "Ransac iteration 6:   accuracy = 0.83144\n",
      "Ransac iteration 7:   accuracy = 0.82944\n",
      "Ransac iteration 8:   accuracy = 0.83211\n",
      "Ransac iteration 9:   accuracy = 0.83244\n",
      "----------------\n",
      "train size: (3110,)\n",
      "Final accuracy = 0.83712\n",
      "----------------\n",
      "################ Outer iteration 3 ################ \n",
      "AL iteration 0:   accuracy = 0.82610\n",
      "AL iteration 1:   accuracy = 0.83178\n",
      "train size: (3310,)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.82744\n",
      "Ransac iteration 1:   accuracy = 0.83077\n",
      "Ransac iteration 2:   accuracy = 0.82744\n",
      "Ransac iteration 3:   accuracy = 0.83745\n",
      "Ransac iteration 4:   accuracy = 0.83511\n",
      "Ransac iteration 5:   accuracy = 0.82877\n",
      "Ransac iteration 6:   accuracy = 0.83478\n",
      "Ransac iteration 7:   accuracy = 0.83311\n",
      "Ransac iteration 8:   accuracy = 0.82844\n",
      "Ransac iteration 9:   accuracy = 0.82577\n",
      "----------------\n",
      "train size: (3144,)\n",
      "Final accuracy = 0.83745\n",
      "----------------\n",
      "################ Outer iteration 4 ################ \n",
      "AL iteration 0:   accuracy = 0.82977\n",
      "AL iteration 1:   accuracy = 0.83111\n",
      "train size: (3344,)\n",
      "--------\n",
      "Ransac iteration 0:   accuracy = 0.82877\n",
      "Ransac iteration 1:   accuracy = 0.82443\n",
      "Ransac iteration 2:   accuracy = 0.82443\n",
      "Ransac iteration 3:   accuracy = 0.83378\n",
      "Ransac iteration 4:   accuracy = 0.82610\n",
      "Ransac iteration 5:   accuracy = 0.83511\n",
      "Ransac iteration 6:   accuracy = 0.82644\n",
      "Ransac iteration 7:   accuracy = 0.82009\n",
      "Ransac iteration 8:   accuracy = 0.82744\n",
      "Ransac iteration 9:   accuracy = 0.83144\n",
      "----------------\n",
      "train size: (3176,)\n",
      "Final accuracy = 0.83511\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "## Active learning with Ransac\n",
    "\n",
    "##################### in total N*k times active learning iterations, N*M times Ransac iterations ##############\n",
    "\n",
    "noise_probability = 0.2\n",
    "K = 2\n",
    "N = 5\n",
    "ambigious_amount = 100    \n",
    "M = 10   #RANSAC\n",
    "ransac_percent = 0.95\n",
    "add_noise_to_train = True  # pool always has noise\n",
    "\n",
    "################################################################################################################\n",
    "X_train, X_pool, X_test, y_train, y_pool, y_test = split_data(scaled_X, y,noise_probability = noise_probability, add_noise_to_train=add_noise_to_train)\n",
    "\n",
    "clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state)\n",
    "clf1.fit(X_train, y_train)\n",
    "acc = clf1.score(X_test,y_test)\n",
    "print (f\"iteration -1:   accuracy = {acc:0.5f}\")\n",
    "print (\"--\")\n",
    "\n",
    "for n in range(N):\n",
    "\n",
    "    print(f\"################ Outer iteration {n} ################ \")\n",
    "\n",
    "    ############ K iteration active learning -> everytime label ambigious_amount data ############\n",
    "    for k in range(K):\n",
    "        X_train, y_train, X_pool, y_pool, clf1, acc = train_one_iter_active_learning(X_train, y_train, X_pool, y_pool, X_test, y_test, clf1, ambigious_amount=ambigious_amount , method='least_confidence')\n",
    "        print (f\"AL iteration {k}:   accuracy = {acc:0.5f}\")\n",
    "    print(f\"train size: {y_train.shape}\")\n",
    "    print (\"--------\")\n",
    "    \n",
    "    ###########################################################################\n",
    "\n",
    "\n",
    "    ############ M iteration RANSAC ###########################################\n",
    "    \n",
    "    stats_history =[]\n",
    "    for m in range(M):\n",
    "        ransac_random_state = random_state + m # to make sure repeatable results\n",
    "\n",
    "        r_X_train,r_X_outlier, r_y_train, r_y_outlier = train_test_split(X_train, y_train, train_size = ransac_percent, random_state = ransac_random_state)\n",
    "        clf1 = MLPClassifier(verbose=0, hidden_layer_sizes=(100,100),random_state = random_state)\n",
    "        clf1.fit(r_X_train, r_y_train)\n",
    "        acc = clf1.score(X_test, y_test)\n",
    "        print (f\"Ransac iteration {m}:   accuracy = {acc:0.5f}\")\n",
    "        \n",
    "        stat = {\"model\":clf1, \"X_train\":r_X_train, \"y_train\":r_y_train, \"accuracy\":acc}\n",
    "        stats_history.append(stat)\n",
    "\n",
    "    # Take the best model and 95% data that gives best accuracy     \n",
    "    best = sorted(stats_history, key=lambda x: x[\"accuracy\"])[-1]\n",
    "    clf1 = best[\"model\"]\n",
    "    X_train = best[\"X_train\"]\n",
    "    y_train = best[\"y_train\"]\n",
    "    acc = best[\"accuracy\"]\n",
    "    print (\"----------------\")\n",
    "\n",
    "    print(f\"train size: {y_train.shape}\")\n",
    "    print (f\"Final accuracy = {acc:0.5f}\")\n",
    "    print (\"----------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}